{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8bP7uAO4LU3"
      },
      "source": [
        "# Word2Vec\n",
        "here I implement word2vec with very simple example using tensorflow  \n",
        "word2vec is vector representation for words with similarity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSpviYfI4LVB"
      },
      "source": [
        "# Collect Data\n",
        "we will use only 10 sentences to create word vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "bDJi6TaM4LVF"
      },
      "outputs": [],
      "source": [
        "corpus = ['king is a strong man',\n",
        "          'queen is a wise woman',\n",
        "          'boy is a young man',\n",
        "          'girl is a young woman',\n",
        "          'prince is a young king',\n",
        "          'princess is a young queen',\n",
        "          'man is strong',\n",
        "          'woman is pretty',\n",
        "          'prince is a boy will be king',\n",
        "          'princess is a girl will be queen',\n",
        "          'king is a strong man',\n",
        "          'queen is a wise woman', \n",
        "          'queen is a beautiful woman', \n",
        "          'king is the most wise man']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idIwgU_o4LVU"
      },
      "source": [
        "# Remove stop words\n",
        "In order for efficiency of creating word vector, we will remove commonly used words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "FJH9-oVl4LVX"
      },
      "outputs": [],
      "source": [
        "def remove_stop_words(corpus):\n",
        "    stop_words = ['is', 'a', 'will', 'be', 'the']\n",
        "    results = []\n",
        "    for text in corpus:\n",
        "        tmp = text.split(' ')\n",
        "        for stop_word in stop_words:\n",
        "            if stop_word in tmp:\n",
        "                tmp.remove(stop_word)\n",
        "        results.append(\" \".join(tmp))\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ZOVxbjAL4LVg"
      },
      "outputs": [],
      "source": [
        "corpus = remove_stop_words(corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBn3vAmjbKH-",
        "outputId": "afe9104d-a092-4305-9988-dbaaef5714ed"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['king strong man',\n",
              " 'queen wise woman',\n",
              " 'boy young man',\n",
              " 'girl young woman',\n",
              " 'prince young king',\n",
              " 'princess young queen',\n",
              " 'man strong',\n",
              " 'woman pretty',\n",
              " 'prince boy king',\n",
              " 'princess girl queen',\n",
              " 'king strong man',\n",
              " 'queen wise woman',\n",
              " 'queen beautiful woman',\n",
              " 'king most wise man']"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAduArsH4LVp",
        "outputId": "634e5fe4-29eb-4dcc-dcf3-2cdc2c96d9cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "king strong man\n",
            "queen wise woman\n",
            "boy young man\n",
            "girl young woman\n",
            "prince young king\n",
            "princess young queen\n",
            "man strong\n",
            "woman pretty\n",
            "prince boy king\n",
            "princess girl queen\n",
            "king strong man\n",
            "queen wise woman\n",
            "queen beautiful woman\n",
            "king most wise man\n",
            "['king', 'strong', 'man', 'queen', 'wise', 'woman', 'boy', 'young', 'man', 'girl', 'young', 'woman', 'prince', 'young', 'king', 'princess', 'young', 'queen', 'man', 'strong', 'woman', 'pretty', 'prince', 'boy', 'king', 'princess', 'girl', 'queen', 'king', 'strong', 'man', 'queen', 'wise', 'woman', 'queen', 'beautiful', 'woman', 'king', 'most', 'wise', 'man']\n",
            "14\n"
          ]
        }
      ],
      "source": [
        "words = []\n",
        "for text in corpus:\n",
        "    print(text)\n",
        "    for word in text.split(' '):\n",
        "        words.append(word)\n",
        "print(words)\n",
        "words = set(words)\n",
        "print(len(words))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDE9Xo6l4LVz"
      },
      "source": [
        "here we have word set by which we will have word vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8JUBrBb34LV2",
        "outputId": "ab3f6aa5-6725-497b-bf48-d753ac15417e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'beautiful',\n",
              " 'boy',\n",
              " 'girl',\n",
              " 'king',\n",
              " 'man',\n",
              " 'most',\n",
              " 'pretty',\n",
              " 'prince',\n",
              " 'princess',\n",
              " 'queen',\n",
              " 'strong',\n",
              " 'wise',\n",
              " 'woman',\n",
              " 'young'}"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVsxhA714LWK"
      },
      "source": [
        "# data generation\n",
        "we will generate label for each word using skip gram.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6MU-R-S9wkRd",
        "outputId": "b7a2ebe7-16a1-403f-c9a8-6e6528817b19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'pretty': 0, 'woman': 1, 'most': 2, 'princess': 3, 'strong': 4, 'king': 5, 'girl': 6, 'queen': 7, 'wise': 8, 'prince': 9, 'boy': 10, 'beautiful': 11, 'young': 12, 'man': 13}\n"
          ]
        }
      ],
      "source": [
        "word2int = {}\n",
        "\n",
        "for i,word in enumerate(words):\n",
        "    word2int[word] = i\n",
        "print(word2int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2DtXVQrv4Ji",
        "outputId": "5eb7720c-2004-4279-f308-8cc8821926dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[['king', 'strong', 'man'], ['queen', 'wise', 'woman'], ['boy', 'young', 'man'], ['girl', 'young', 'woman'], ['prince', 'young', 'king'], ['princess', 'young', 'queen'], ['man', 'strong'], ['woman', 'pretty'], ['prince', 'boy', 'king'], ['princess', 'girl', 'queen'], ['king', 'strong', 'man'], ['queen', 'wise', 'woman'], ['queen', 'beautiful', 'woman'], ['king', 'most', 'wise', 'man']]\n"
          ]
        }
      ],
      "source": [
        "sentences = []\n",
        "for sentence in corpus:\n",
        "    sentences.append(sentence.split())\n",
        "print(sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKK4fVZS4LWN",
        "outputId": "b5e504ba-5250-4235-cc25-7b68333d41c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['king', 'strong']\n",
            "['king', 'man']\n",
            "['strong', 'king']\n",
            "['strong', 'man']\n",
            "['man', 'king']\n",
            "['man', 'strong']\n",
            "['queen', 'wise']\n",
            "['queen', 'woman']\n",
            "['wise', 'queen']\n",
            "['wise', 'woman']\n",
            "['woman', 'queen']\n",
            "['woman', 'wise']\n",
            "['boy', 'young']\n",
            "['boy', 'man']\n",
            "['young', 'boy']\n",
            "['young', 'man']\n",
            "['man', 'boy']\n",
            "['man', 'young']\n",
            "['girl', 'young']\n",
            "['girl', 'woman']\n",
            "['young', 'girl']\n",
            "['young', 'woman']\n",
            "['woman', 'girl']\n",
            "['woman', 'young']\n",
            "['prince', 'young']\n",
            "['prince', 'king']\n",
            "['young', 'prince']\n",
            "['young', 'king']\n",
            "['king', 'prince']\n",
            "['king', 'young']\n",
            "['princess', 'young']\n",
            "['princess', 'queen']\n",
            "['young', 'princess']\n",
            "['young', 'queen']\n",
            "['queen', 'princess']\n",
            "['queen', 'young']\n",
            "['man', 'strong']\n",
            "['strong', 'man']\n",
            "['woman', 'pretty']\n",
            "['pretty', 'woman']\n",
            "['prince', 'boy']\n",
            "['prince', 'king']\n",
            "['boy', 'prince']\n",
            "['boy', 'king']\n",
            "['king', 'prince']\n",
            "['king', 'boy']\n",
            "['princess', 'girl']\n",
            "['princess', 'queen']\n",
            "['girl', 'princess']\n",
            "['girl', 'queen']\n",
            "['queen', 'princess']\n",
            "['queen', 'girl']\n",
            "['king', 'strong']\n",
            "['king', 'man']\n",
            "['strong', 'king']\n",
            "['strong', 'man']\n",
            "['man', 'king']\n",
            "['man', 'strong']\n",
            "['queen', 'wise']\n",
            "['queen', 'woman']\n",
            "['wise', 'queen']\n",
            "['wise', 'woman']\n",
            "['woman', 'queen']\n",
            "['woman', 'wise']\n",
            "['queen', 'beautiful']\n",
            "['queen', 'woman']\n",
            "['beautiful', 'queen']\n",
            "['beautiful', 'woman']\n",
            "['woman', 'queen']\n",
            "['woman', 'beautiful']\n",
            "['king', 'most']\n",
            "['king', 'wise']\n",
            "['most', 'king']\n",
            "['most', 'wise']\n",
            "['most', 'man']\n",
            "['wise', 'king']\n",
            "['wise', 'most']\n",
            "['wise', 'man']\n",
            "['man', 'most']\n",
            "['man', 'wise']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "WINDOW_SIZE = 2\n",
        "\n",
        "data = []\n",
        "for sentence in sentences:\n",
        "    for idx, word in enumerate(sentence):\n",
        "        for neighbor in sentence[max(idx - WINDOW_SIZE, 0) : min(idx + WINDOW_SIZE, len(sentence)) + 1] :\n",
        "            if neighbor != word:\n",
        "                data.append([word, neighbor])\n",
        "for d in data:\n",
        "  print(d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YaX0FU2b4LWZ",
        "outputId": "0e4db7bf-30fb-4084-ad64-f48d16f887b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     input   label\n",
            "0     king  strong\n",
            "1     king     man\n",
            "2   strong    king\n",
            "3   strong     man\n",
            "4      man    king\n",
            "..     ...     ...\n",
            "75    wise    king\n",
            "76    wise    most\n",
            "77    wise     man\n",
            "78     man    most\n",
            "79     man    wise\n",
            "\n",
            "[80 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame(data, columns = ['input', 'label'])\n",
        "print(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "Q6izT_w_4LWq",
        "outputId": "a90812de-f79b-41e4-e684-e78844540986"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>input</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>king</td>\n",
              "      <td>strong</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>king</td>\n",
              "      <td>man</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>strong</td>\n",
              "      <td>king</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>strong</td>\n",
              "      <td>man</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>man</td>\n",
              "      <td>king</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>man</td>\n",
              "      <td>strong</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>queen</td>\n",
              "      <td>wise</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>queen</td>\n",
              "      <td>woman</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>wise</td>\n",
              "      <td>queen</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>wise</td>\n",
              "      <td>woman</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    input   label\n",
              "0    king  strong\n",
              "1    king     man\n",
              "2  strong    king\n",
              "3  strong     man\n",
              "4     man    king\n",
              "5     man  strong\n",
              "6   queen    wise\n",
              "7   queen   woman\n",
              "8    wise   queen\n",
              "9    wise   woman"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "fU16FHiD4LW5",
        "outputId": "4755a017-5a6b-40e0-b91e-d747abad604c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(80, 2)"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2lh9K8VL4LXI",
        "outputId": "4f2f7ed4-b692-4682-aa68-50869fdfb3eb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'pretty': 0,\n",
              " 'woman': 1,\n",
              " 'most': 2,\n",
              " 'princess': 3,\n",
              " 'strong': 4,\n",
              " 'king': 5,\n",
              " 'girl': 6,\n",
              " 'queen': 7,\n",
              " 'wise': 8,\n",
              " 'prince': 9,\n",
              " 'boy': 10,\n",
              " 'beautiful': 11,\n",
              " 'young': 12,\n",
              " 'man': 13}"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "word2int"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zd8nKNkn4LXY"
      },
      "source": [
        "# Define Tensorflow Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "FwcVsy6qedsI"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-02-17 10:21:40.826728: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-02-17 10:21:40.855262: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2025-02-17 10:21:41.008296: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2025-02-17 10:21:41.008353: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2025-02-17 10:21:41.009089: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-02-17 10:21:41.072096: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2025-02-17 10:21:41.073944: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-02-17 10:21:42.784772: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "printing X: [array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]), array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]), array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]), array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]), array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]), array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]), array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]), array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]), array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]), array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]), array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.])]\n",
            "printing Y: [array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]), array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]), array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]), array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]), array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]), array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]), array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]), array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]), array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]), array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]), array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]), array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]), array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]), array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]), array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]), array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]), array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]), array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]), array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]), array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.])]\n"
          ]
        }
      ],
      "source": [
        "ONE_HOT_DIM = len(words)\n",
        "\n",
        "def one_hot_encode(data_point_index):\n",
        "    one_hot_vector = np.zeros(ONE_HOT_DIM)\n",
        "    one_hot_vector[data_point_index] = 1\n",
        "    return one_hot_vector\n",
        "\n",
        "\n",
        "X = []\n",
        "Y = []\n",
        "for x, y in zip(df['input'], df['label']):\n",
        "    X.append(one_hot_encode(word2int[x]))\n",
        "    Y.append(one_hot_encode(word2int[y]))\n",
        "    \n",
        "print(f\"printing X: {X}\")\n",
        "print(f\"printing Y: {Y}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "ojMB3dJX4LXc",
        "outputId": "badd453b-bc4e-43e7-89d0-d4fc2f31863c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.linalg.matmul_12), but are not present in its tracked objects:   <tf.Variable 'Variable:0' shape=(14, 2) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
            "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.math.add_12), but are not present in its tracked objects:   <tf.Variable 'Variable:0' shape=(1,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
            "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.linalg.matmul_13), but are not present in its tracked objects:   <tf.Variable 'Variable:0' shape=(2, 14) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.math.add_13), but are not present in its tracked objects:   <tf.Variable 'Variable:0' shape=(1,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "`tape` is required when a `Tensor` loss is passed. Received: loss=KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='tf.keras.backend.categorical_crossentropy/Neg:0', description=\"created by layer 'tf.keras.backend.categorical_crossentropy'\"), tape=None.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Input \u001b[0;32mIn [35]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m loss \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mcategorical_crossentropy(y_label, prediction)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# training operation\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m train_op \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSGD\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.05\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvar_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mW1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb2\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/optimizers/optimizer.py:543\u001b[0m, in \u001b[0;36m_BaseOptimizer.minimize\u001b[0;34m(self, loss, var_list, tape)\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mminimize\u001b[39m(\u001b[38;5;28mself\u001b[39m, loss, var_list, tape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    523\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Minimize `loss` by updating `var_list`.\u001b[39;00m\n\u001b[1;32m    524\u001b[0m \n\u001b[1;32m    525\u001b[0m \u001b[38;5;124;03m    This method simply computes gradient using `tf.GradientTape` and calls\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;124;03m      None\u001b[39;00m\n\u001b[1;32m    542\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 543\u001b[0m     grads_and_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvar_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    544\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_gradients(grads_and_vars)\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/optimizers/optimizer.py:262\u001b[0m, in \u001b[0;36m_BaseOptimizer.compute_gradients\u001b[0;34m(self, loss, var_list, tape)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute gradients of loss on trainable variables.\u001b[39;00m\n\u001b[1;32m    245\u001b[0m \n\u001b[1;32m    246\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;124;03m  gradient can be `None`.\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(loss) \u001b[38;5;129;01mand\u001b[39;00m tape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 262\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    263\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tape` is required when a `Tensor` loss is passed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    264\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived: loss=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, tape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    265\u001b[0m     )\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    267\u001b[0m     tape \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mGradientTape()\n",
            "\u001b[0;31mValueError\u001b[0m: `tape` is required when a `Tensor` loss is passed. Received: loss=KerasTensor(type_spec=TensorSpec(shape=(None,), dtype=tf.float32, name=None), name='tf.keras.backend.categorical_crossentropy/Neg:0', description=\"created by layer 'tf.keras.backend.categorical_crossentropy'\"), tape=None."
          ]
        }
      ],
      "source": [
        "X_train = np.asarray(X)\n",
        "Y_train = np.asarray(Y)\n",
        "\n",
        "# making inputs for X_train and Y_train using keras Input layer\n",
        "x = tf.keras.Input(shape=(ONE_HOT_DIM,))\n",
        "y_label = tf.keras.Input(shape=(ONE_HOT_DIM,))\n",
        "\n",
        "# Create model using Keras Sequential API\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(EMBEDDING_DIM, input_shape=(ONE_HOT_DIM,)),\n",
        "    tf.keras.layers.Dense(ONE_HOT_DIM, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=0.05)\n",
        "model.compile(optimizer=optimizer,\n",
        "             loss='categorical_crossentropy',\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, Y_train, \n",
        "                   epochs=20000,\n",
        "                   verbose=1,\n",
        "                   batch_size=len(X_train))\n",
        "\n",
        "# Get the word embeddings (they're in the first layer's weights)\n",
        "word_vectors = model.layers[0].get_weights()[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LodzfyCr09AJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "id": "AT3jTu8s3v40",
        "outputId": "9a8f66a7-6343-471e-a7d5-3ee744a912ff"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-cf330ca24c33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword2int\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mman\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'man' is not defined"
          ]
        }
      ],
      "source": [
        "print(word2int['man'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4EJjFSc4LXn"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "id": "Gh9tvp7Z4LXu",
        "outputId": "722e7fa8-0b5e-4d65-e5c6-429a496063cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "iteration 0 loss is :  3.3874831\n",
            "iteration 3000 loss is :  1.7615176\n",
            "iteration 6000 loss is :  1.7135644\n",
            "iteration 9000 loss is :  1.6936957\n",
            "iteration 12000 loss is :  1.6818337\n",
            "iteration 15000 loss is :  1.6735965\n",
            "iteration 18000 loss is :  1.667389\n"
          ]
        }
      ],
      "source": [
        "sess = tf.Session()\n",
        "init = tf.global_variables_initializer()\n",
        "sess.run(init)\n",
        "\n",
        "iteration = 20000\n",
        "for i in range(iteration):\n",
        "    # input is X_train which is one hot encoded word\n",
        "    # label is Y_train which is one hot encoded neighbor word\n",
        "    sess.run(train_op, feed_dict={x: X_train, y_label: Y_train})\n",
        "    if i % 3000 == 0:\n",
        "        print('iteration '+str(i)+' loss is : ', sess.run(loss, feed_dict={x: X_train, y_label: Y_train}))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "UJuYLAEW4LYA",
        "outputId": "0047b846-b471-4974-c104-957ef4d043db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 4.375873    0.16186821]\n",
            " [ 0.19360328  1.7890494 ]\n",
            " [ 6.1193333  -0.08758414]\n",
            " [-1.2201542   4.6891165 ]\n",
            " [-0.20656192 -0.23423088]\n",
            " [-0.01745999  5.9915733 ]\n",
            " [-2.5089917  -0.02818429]\n",
            " [ 4.438786   -2.2695527 ]\n",
            " [-0.3406      1.524016  ]\n",
            " [ 1.0877191  -0.10649729]\n",
            " [-0.20683467  0.7571343 ]\n",
            " [ 1.1867361  -0.2494669 ]]\n"
          ]
        }
      ],
      "source": [
        "# Now the hidden layer (W1 + b1) is actually the word look up table\n",
        "vectors = sess.run(W1 + b1)\n",
        "print(vectors)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnFJAUJD4LYR"
      },
      "source": [
        "# word vector in table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "id": "VazGtYdN4LYU",
        "outputId": "936b67a0-6557-4c0c-b12a-1d0528e7f560"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>x1</th>\n",
              "      <th>x2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>man</td>\n",
              "      <td>4.375873</td>\n",
              "      <td>0.161868</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>woman</td>\n",
              "      <td>0.193603</td>\n",
              "      <td>1.789049</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>prince</td>\n",
              "      <td>6.119333</td>\n",
              "      <td>-0.087584</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>wise</td>\n",
              "      <td>-1.220154</td>\n",
              "      <td>4.689116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>young</td>\n",
              "      <td>-0.206562</td>\n",
              "      <td>-0.234231</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>princess</td>\n",
              "      <td>-0.017460</td>\n",
              "      <td>5.991573</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>pretty</td>\n",
              "      <td>-2.508992</td>\n",
              "      <td>-0.028184</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>strong</td>\n",
              "      <td>4.438786</td>\n",
              "      <td>-2.269553</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>girl</td>\n",
              "      <td>-0.340600</td>\n",
              "      <td>1.524016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>king</td>\n",
              "      <td>1.087719</td>\n",
              "      <td>-0.106497</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>queen</td>\n",
              "      <td>-0.206835</td>\n",
              "      <td>0.757134</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>boy</td>\n",
              "      <td>1.186736</td>\n",
              "      <td>-0.249467</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        word        x1        x2\n",
              "0        man  4.375873  0.161868\n",
              "1      woman  0.193603  1.789049\n",
              "2     prince  6.119333 -0.087584\n",
              "3       wise -1.220154  4.689116\n",
              "4      young -0.206562 -0.234231\n",
              "5   princess -0.017460  5.991573\n",
              "6     pretty -2.508992 -0.028184\n",
              "7     strong  4.438786 -2.269553\n",
              "8       girl -0.340600  1.524016\n",
              "9       king  1.087719 -0.106497\n",
              "10     queen -0.206835  0.757134\n",
              "11       boy  1.186736 -0.249467"
            ]
          },
          "execution_count": 14,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "w2v_df = pd.DataFrame(vectors, columns = ['x1', 'x2'])\n",
        "w2v_df['word'] = words\n",
        "w2v_df = w2v_df[['word', 'x1', 'x2']]\n",
        "w2v_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ka1xehB04LYs"
      },
      "source": [
        "# word vector in 2d chart"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "kVPs8UrX4LYy",
        "outputId": "52a29080-a537-4e2d-aac7-9b123f397c63"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "for word, x1, x2 in zip(w2v_df['word'], w2v_df['x1'], w2v_df['x2']):\n",
        "    ax.annotate(word, (x1,x2 ))\n",
        "\n",
        "PADDING = 1.0\n",
        "x_axis_min = np.amin(vectors, axis=0)[0] - PADDING\n",
        "y_axis_min = np.amin(vectors, axis=0)[1] - PADDING\n",
        "x_axis_max = np.amax(vectors, axis=0)[0] + PADDING\n",
        "y_axis_max = np.amax(vectors, axis=0)[1] + PADDING\n",
        "\n",
        "plt.xlim(x_axis_min,x_axis_max)\n",
        "plt.ylim(y_axis_min,y_axis_max)\n",
        "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rW1loNqL4LZI"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
