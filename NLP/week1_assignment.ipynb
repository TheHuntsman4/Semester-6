{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/the_architect/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/the_architect/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/the_architect/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from googletrans import Translator\n",
    "import spacy\n",
    "from gtts import gTTS\n",
    "import os\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Write chatbot description to file\n",
    "chatbot_text = \"\"\"ChatGPT is a sophisticated AI language model developed by OpenAI. It serves as a versatile conversational agent capable of understanding and generating human-like text responses. The chatbot uses advanced natural language processing techniques and was trained on vast amounts of internet text data. ChatGPT can assist users with various tasks including writing, coding, answering questions, and providing explanations. It has found applications in customer service, education, content creation, and technical support. The model works by processing input text through multiple transformer layers and generating contextually relevant responses.\"\"\"\n",
    "\n",
    "with open('chatbot.txt', 'w') as f:\n",
    "    f.write(chatbot_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentences:\n",
      "1. ChatGPT is a sophisticated AI language model developed by OpenAI.\n",
      "2. It serves as a versatile conversational agent capable of understanding and generating human-like text responses.\n",
      "3. The chatbot uses advanced natural language processing techniques and was trained on vast amounts of internet text data.\n",
      "4. ChatGPT can assist users with various tasks including writing, coding, answering questions, and providing explanations.\n",
      "5. It has found applications in customer service, education, content creation, and technical support.\n",
      "6. The model works by processing input text through multiple transformer layers and generating contextually relevant responses.\n",
      "\n",
      "Words:\n",
      "['ChatGPT', 'is', 'a', 'sophisticated', 'AI', 'language', 'model', 'developed', 'by', 'OpenAI', '.', 'It', 'serves', 'as', 'a', 'versatile', 'conversational', 'agent', 'capable', 'of', 'understanding', 'and', 'generating', 'human-like', 'text', 'responses', '.', 'The', 'chatbot', 'uses', 'advanced', 'natural', 'language', 'processing', 'techniques', 'and', 'was', 'trained', 'on', 'vast', 'amounts', 'of', 'internet', 'text', 'data', '.', 'ChatGPT', 'can', 'assist', 'users', 'with', 'various', 'tasks', 'including', 'writing', ',', 'coding', ',', 'answering', 'questions', ',', 'and', 'providing', 'explanations', '.', 'It', 'has', 'found', 'applications', 'in', 'customer', 'service', ',', 'education', ',', 'content', 'creation', ',', 'and', 'technical', 'support', '.', 'The', 'model', 'works', 'by', 'processing', 'input', 'text', 'through', 'multiple', 'transformer', 'layers', 'and', 'generating', 'contextually', 'relevant', 'responses', '.']\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Process text into sentences and words\n",
    "with open('chatbot.txt', 'r') as f:\n",
    "    text = f.read()\n",
    "\n",
    "sentences = sent_tokenize(text)\n",
    "words = word_tokenize(text)\n",
    "\n",
    "print(\"Sentences:\")\n",
    "for i, sent in enumerate(sentences, 1):\n",
    "    print(f\"{i}. {sent}\")\n",
    "\n",
    "print(\"\\nWords:\")\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Remove stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_words = [word for word in words if word.lower() not in stop_words and word.isalnum()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Word Count Summary:\n",
      "Stop words: 24\n",
      "Content words: 62\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Count stop words and non-stop words\n",
    "stop_word_count = len([word for word in words if word.lower() in stop_words and word.isalnum()])\n",
    "non_stop_word_count = len(filtered_words)\n",
    "\n",
    "print(\"\\nWord Count Summary:\")\n",
    "print(f\"Stop words: {stop_word_count}\")\n",
    "print(f\"Content words: {non_stop_word_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Translations (to Hindi):\n",
      "ChatGPT: चटपट\n",
      "sophisticated: जटिल\n",
      "AI: यह\n",
      "language: भाषा\n",
      "model: नमूना\n",
      "developed: विकसित\n",
      "OpenAI: ओपनई\n",
      "serves: काम करना\n",
      "versatile: बहुमुखी\n",
      "conversational: संवादी\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 5: Translate 10 selected words\n",
    "translator = Translator()\n",
    "selected_words = filtered_words[:10]  # Take first 10 filtered words\n",
    "\n",
    "print(\"\\nTranslations (to Hindi):\")\n",
    "for word in selected_words:\n",
    "    translation = await translator.translate(word, dest='hi')\n",
    "    print(f\"{word}: {translation.text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Named Entities:\n",
      "ChatGPT: ORG\n",
      "AI: ORG\n",
      "OpenAI: GPE\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Named Entity Recognition\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(text)\n",
    "\n",
    "print(\"\\nNamed Entities:\")\n",
    "for ent in doc.ents:\n",
    "    print(f\"{ent.text}: {ent.label_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Audio file saved as 'chatbot_speech.mp3'\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Convert to speech\n",
    "tts = gTTS(text=text, lang='en')\n",
    "tts.save(\"chatbot_speech.mp3\")\n",
    "print(\"\\nAudio file saved as 'chatbot_speech.mp3'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
